{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval as me\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file0, sr = sf.read(\"./mir_eval test/mixture.wav\" )\\nfile1, _ = sf.read(\"./mir_eval test/bass.wav\")\\nfile2, _ = sf.read(\"./mir_eval test/drums.wav\")\\nfile3, _ = sf.read(\"./mir_eval test/vocals.wav\")\\nfile4, _ = sf.read(\"./mir_eval test/other.wav\")\\n\\nreference_sources = np.array([file0, file1])\\nestimated_sources = np.array([file2, file3])\\nreference_sources'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''file0, sr = sf.read(\"./mir_eval test/mixture.wav\" )\n",
    "file1, _ = sf.read(\"./mir_eval test/bass.wav\")\n",
    "file2, _ = sf.read(\"./mir_eval test/drums.wav\")\n",
    "file3, _ = sf.read(\"./mir_eval test/vocals.wav\")\n",
    "file4, _ = sf.read(\"./mir_eval test/other.wav\")\n",
    "\n",
    "reference_sources = np.array([file0, file1])\n",
    "estimated_sources = np.array([file2, file3])\n",
    "reference_sources'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sources, _ = sf.read(\"./mir_eval test/from mek/vocals_downsampled.wav\")\n",
    "estimated_sources, _ = sf.read(\"./mir_eval test/from mek/vocal_05.wav\")\n",
    "mix_sources, _ = sf.read(\"./mir_eval test/from mek/mix_05.wav\")\n",
    "\n",
    "reference_sources = np.array([reference_sources, reference_sources])\n",
    "estimated_sources = np.array([estimated_sources, estimated_sources])\n",
    "mix_sources = np.array([mix_sources, mix_sources])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Metrics\n",
    "\n",
    "https://craffel.github.io/mir_eval/#module-mir_eval.separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Evaluate\n",
    "Computes ```bss_eval_sources``` (for fewer than 3 dimensions) and ```bss_eval_images```.\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.evaluate(reference_sources, estimated_sources, **kwargs)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "\t\n",
    "- **scores:** ```dict```, dictionary of scores, where the key is the metric name (str) and the value is the (float) score achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Blind Source Separation (BSS)\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)\n",
    "```\n",
    "\n",
    "#### Use\n",
    "\n",
    "From \"WAVE-U-NET: A MULTI-SCALE NEURAL NETWORK FOR END-TO-END AUDIO SOURCE SEPARATION\"\n",
    "\n",
    "_Since the collection of segment-wise vocal SDR values across the dataset is not normally distributed (compare Fig- ure 3 for vocals), the mean and standard deviation are not sufficient to adequately summarise it. As a workaround, **we take the median over segments**, as it is robust against outliers and intuitively describes the minimum performance that is achieved 50% of the time. To describe the spread of the distribution, we use the median absolute deviation (MAD) as a rank-based equivalent to the standard deviation (SD). It is defined as the median of the absolute deviations from the overall median and is easily interpretable, since a value of x means that 50% of values have an absolute difference from the median that is lower than x._\n",
    "\n",
    "#### Returns\n",
    "\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "\n",
    "- perm: not used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized SDR (NSDR)\n",
    "\n",
    "$NSDR(S_e, S_r, S_m) = SDR(S_e, S_r) - SDR(S_m, S_r)$\n",
    "\n",
    "where $S_e$ is the estimated isolated signal, $S_r$ is the reference isolated signal, and $S_m$ is the mixed signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsdr(reference_sources, estimated_sources, mix_sources):\n",
    "    sdr1, _, _, _ = me.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)\n",
    "    sdr2, _, _, _ = me.separation.bss_eval_sources(reference_sources, mix_sources, compute_permutation=True)\n",
    "    \n",
    "    return sdr1 - sdr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, sir, sar, _ = me.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227.98471633, 227.98471633])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.10238682, 4.10238682])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.18227768, 8.18227768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_out = nsdr(reference_sources, estimated_sources, mix_sources)\n",
    "nsdr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Image to spatial distortion\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_images(reference_sources, estimated_sources, compute_permutation=True)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **isr:** ```np.ndarray, shape=(nsrc,)```, vector of source Image to Spatial distortion Ratios (ISR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "\n",
    "- perm: not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, isr, sir, sar, _ = me.separation.bss_eval_images(reference_sources, estimated_sources, compute_permutation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227.98471633, 227.98471633])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.10238682, 4.10238682])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.18227768, 8.18227768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_out = nsdr(reference_sources, estimated_sources, mix_sources)\n",
    "nsdr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Image to spatial distortion framewise\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_images_framewise(reference_sources, estimated_sources, window=1323000, hop=661500, compute_permutation=False)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "\n",
    "- perm: not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, isr, sir, sar, _ = me.separation.bss_eval_images_framewise(reference_sources, \n",
    "                                                              estimated_sources, \n",
    "                                                              window=1323000, \n",
    "                                                              hop=661500, \n",
    "                                                              compute_permutation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[227.98471633],\n",
       "       [227.98471633]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.10238682],\n",
       "       [4.10238682]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.18227768, 8.18227768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_out = nsdr(reference_sources, estimated_sources, mix_sources)\n",
    "nsdr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "#### Validate input data\n",
    "\n",
    "Checks that the input data to a metric are valid, and throws helpful errors if not.\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.validate(reference_sources, estimated_sources)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.separation.validate(reference_sources, estimated_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Evaluate all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NSDR Vocal': 8.182277682555021,\n",
       " 'NSDR Instrumental': None,\n",
       " 'SIR Vocal': 227.98471632599598,\n",
       " 'SIR Instrumental': None,\n",
       " 'SAR Vocal': 4.10238682484913,\n",
       " 'SAR Instrumental': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, sirs, sars, _ = me.separation.bss_eval_sources(reference_sources, \n",
    "                                                     estimated_sources, \n",
    "                                                     compute_permutation=True)\n",
    "\n",
    "nsdrs = nsdr(reference_sources, estimated_sources, mix_sources)\n",
    "\n",
    "means = {\n",
    "    'NSDR Vocal': np.mean(nsdrs),\n",
    "    'NSDR Instrumental': None,\n",
    "    'SIR Vocal': np.mean(sirs),\n",
    "    'SIR Instrumental': None,\n",
    "    'SAR Vocal': np.mean(sars),\n",
    "    'SAR Instrumental': None\n",
    "}\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Comparison with MIREX results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mired_results = {\n",
    "    'NSDR Vocal': 8.681,\n",
    "    'NSDR Instrumental': 7.945,\n",
    "    'SIR Vocal': 15.308,\n",
    "    'SIR Instrumental': 21.975,\n",
    "    'SAR Vocal': 11.301,\n",
    "    'SAR Instrumental': 15.462\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
