{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval as me\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2094534, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file0, sr = sf.read(\"./mir_eval test/mixture.wav\" )\n",
    "file1, _ = sf.read(\"./mir_eval test/bass.wav\")\n",
    "file2, _ = sf.read(\"./mir_eval test/drums.wav\")\n",
    "file3, _ = sf.read(\"./mir_eval test/vocals.wav\")\n",
    "file4, _ = sf.read(\"./mir_eval test/other.wav\")\n",
    "\n",
    "mix = file1+file2+file3+file4\n",
    "#sd.play(mix, sample_rate)\n",
    "reference_sources = np.array([file0, file1])\n",
    "estimated_sources = np.array([file2, file3])\n",
    "reference_sources.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Metrics\n",
    "\n",
    "https://craffel.github.io/mir_eval/#module-mir_eval.separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Evaluate\n",
    "Computes ```bss_eval_sources``` (for fewer than 3 dimensions) and ```bss_eval_images```.\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.evaluate(reference_sources, estimated_sources, **kwargs)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "\t\n",
    "- **scores:** ```dict```, dictionary of scores, where the key is the metric name (str) and the value is the (float) score achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Blind Source Separation (BSS)\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)\n",
    "```\n",
    "\n",
    "#### Use\n",
    "\n",
    "From \"WAVE-U-NET: A MULTI-SCALE NEURAL NETWORK FOR END-TO-END AUDIO SOURCE SEPARATION\"\n",
    "\n",
    "_Since the collection of segment-wise vocal SDR values across the dataset is not normally distributed (compare Fig- ure 3 for vocals), the mean and standard deviation are not sufficient to adequately summarise it. As a workaround, **we take the median over segments**, as it is robust against outliers and intuitively describes the minimum performance that is achieved 50% of the time. To describe the spread of the distribution, we use the median absolute deviation (MAD) as a rank-based equivalent to the standard deviation (SD). It is defined as the median of the absolute deviations from the overall median and is easily interpretable, since a value of x means that 50% of values have an absolute difference from the median that is lower than x._\n",
    "\n",
    "#### Returns\n",
    "\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Image to spatial distortion\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_images(reference_sources, estimated_sources, compute_permutation=True)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "#### Normalized SDR (NSDR)\n",
    "\n",
    "$NSDR(S_e, S_r, S_m) = SDR(S_e, S_r) - SDR(S_m, S_r)$\n",
    "\n",
    "where $S_e$ is the estimated isolated signal, $S_r$ is the reference isolated signal, and $S_m$ is the mixed signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, sir, _, _, _ = me.separation.bss_eval_images(reference_sources, estimated_sources, compute_permutation=True)\n",
    "sdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Image to spatial distortion framewise\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_images_framewise(reference_sources, estimated_sources, window=1323000, hop=661500, compute_permutation=False)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "#### Validate input data\n",
    "\n",
    "Checks that the input data to a metric are valid, and throws helpful errors if not.\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.validate(reference_sources, estimated_sources)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.separation.validate(reference_sources, estimated_sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
