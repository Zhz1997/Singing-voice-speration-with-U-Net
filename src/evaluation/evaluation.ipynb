{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval as me\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file0, sr = sf.read(\"./mir_eval test/mixture.wav\" )\\nfile1, _ = sf.read(\"./mir_eval test/bass.wav\")\\nfile2, _ = sf.read(\"./mir_eval test/drums.wav\")\\nfile3, _ = sf.read(\"./mir_eval test/vocals.wav\")\\nfile4, _ = sf.read(\"./mir_eval test/other.wav\")\\n\\nreference_sources = np.array([file0, file1])\\nestimated_sources = np.array([file2, file3])\\nreference_sources'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''file0, sr = sf.read(\"./mir_eval test/mixture.wav\" )\n",
    "file1, _ = sf.read(\"./mir_eval test/bass.wav\")\n",
    "file2, _ = sf.read(\"./mir_eval test/drums.wav\")\n",
    "file3, _ = sf.read(\"./mir_eval test/vocals.wav\")\n",
    "file4, _ = sf.read(\"./mir_eval test/other.wav\")\n",
    "\n",
    "reference_sources = np.array([file0, file1])\n",
    "estimated_sources = np.array([file2, file3])\n",
    "reference_sources'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_src_mixes = []\n",
    "ref_src_vocals = []\n",
    "est_src_vocals = []\n",
    "ref_src_acc = []\n",
    "est_src_acc = []\n",
    "\n",
    "for filename in os.listdir('../../wav_files/'):\n",
    "    if 'mix' in filename:\n",
    "        f, _ = sf.read('../../wav_files/' + filename)\n",
    "        ref_src_mixes.append(f)\n",
    "    elif 'vocal_sample' in filename:\n",
    "        f, _ = sf.read('../../wav_files/' + filename)\n",
    "        est_src_vocals.append(f)\n",
    "    elif 'vocals' in filename:\n",
    "        f, _ = sf.read('../../wav_files/' + filename)\n",
    "        ref_src_vocals.append(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('../../wav_files/predicted_acc'):\n",
    "    f, _ = sf.read('../../wav_files/predicted_acc/' + filename)\n",
    "    est_src_acc.append(f)\n",
    "    \n",
    "for filename in os.listdir('../../wav_files/truth_acc'):\n",
    "    f, _ = sf.read('../../wav_files/truth_acc/' + filename)\n",
    "    ref_src_acc.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_src_mixes = np.array(ref_src_mixes)\n",
    "ref_src_vocals = np.array(ref_src_vocals)\n",
    "est_src_vocals = np.array(est_src_vocals)\n",
    "ref_src_acc = np.array(ref_src_acc)\n",
    "est_src_acc = np.array(est_src_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 97536)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_src_vocals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_src_mixes_clean = []\n",
    "ref_src_vocals_clean = []\n",
    "est_src_vocals_clean = []\n",
    "\n",
    "for i in range(est_src_vocals.shape[0]):\n",
    "    if np.count_nonzero(ref_src_vocals[i]):\n",
    "        #print(est_src_vocals[i])\n",
    "        ref_src_mixes_clean.append(ref_src_mixes[i])\n",
    "        ref_src_vocals_clean.append(ref_src_vocals[i])\n",
    "        est_src_vocals_clean.append(est_src_vocals[i])\n",
    "        \n",
    "ref_src_mixes_clean = np.array(ref_src_mixes_clean)\n",
    "ref_src_vocals_clean = np.array(ref_src_vocals_clean)\n",
    "est_src_vocals_clean = np.array(est_src_vocals_clean)\n",
    "type(ref_src_mixes_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 97536)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_src_vocals_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accompaniment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_acc, sir_acc, sar_acc, _ = me.separation.bss_eval_sources(\n",
    "                                                                    ref_src_acc[0:k], \n",
    "                                                                    est_src_acc[0:k], \n",
    "                                                                    compute_permutation=True\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.21161343, 12.26606025,  9.82189987])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.17830162, 35.38705424, 32.41358359, 31.32587624,  8.88463086])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_out = nsdr(sdr_acc, ref_src_acc[0:k], est_src_acc[0:k], ref_src_mixes[0:k])\n",
    "nsdr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_vocal, sir_vocal, sar_vocal, _ = me.separation.bss_eval_sources(\n",
    "                                                                    ref_src_vocals_clean[0:k], \n",
    "                                                                    ref_src_vocals_clean[0:k], \n",
    "                                                                    compute_permutation=True\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.89981343, -14.23884721, -13.52302672, -12.35486897,\n",
       "       -14.58652306, -12.83262392, -12.73266704, -13.41414619,\n",
       "       -14.04276628])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_vocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([287.21807371, 283.79282929, 301.62199315])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_out = nsdr(sdr_vocal, ref_src_vocals_clean[0:k], ref_src_vocals_clean[0:k], ref_src_mixes_clean[0:k])\n",
    "nsdr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Metrics\n",
    "\n",
    "https://craffel.github.io/mir_eval/#module-mir_eval.separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Evaluate\n",
    "Computes ```bss_eval_sources``` (for fewer than 3 dimensions) and ```bss_eval_images```.\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.evaluate(reference_sources, estimated_sources, **kwargs)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "\t\n",
    "- **scores:** ```dict```, dictionary of scores, where the key is the metric name (str) and the value is the (float) score achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Blind Source Separation (BSS)\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)\n",
    "```\n",
    "\n",
    "#### Use\n",
    "\n",
    "From \"WAVE-U-NET: A MULTI-SCALE NEURAL NETWORK FOR END-TO-END AUDIO SOURCE SEPARATION\"\n",
    "\n",
    "_Since the collection of segment-wise vocal SDR values across the dataset is not normally distributed (compare Fig- ure 3 for vocals), the mean and standard deviation are not sufficient to adequately summarise it. As a workaround, **we take the median over segments**, as it is robust against outliers and intuitively describes the minimum performance that is achieved 50% of the time. To describe the spread of the distribution, we use the median absolute deviation (MAD) as a rank-based equivalent to the standard deviation (SD). It is defined as the median of the absolute deviations from the overall median and is easily interpretable, since a value of x means that 50% of values have an absolute difference from the median that is lower than x._\n",
    "\n",
    "#### Returns\n",
    "\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "\n",
    "- perm: not used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized SDR (NSDR)\n",
    "\n",
    "$NSDR(S_e, S_r, S_m) = SDR(S_e, S_r) - SDR(S_m, S_r)$\n",
    "\n",
    "where $S_e$ is the estimated isolated signal, $S_r$ is the reference isolated signal, and $S_m$ is the mixed signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsdr(sdr, reference_sources, estimated_sources, mix_sources):\n",
    "    if (False):\n",
    "        sdr1, _, _, _ = me.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)\n",
    "        sdr2, _, _, _ = me.separation.bss_eval_sources(reference_sources, mix_sources, compute_permutation=True)\n",
    "    else:\n",
    "        sdr1 = sdr\n",
    "        sdr2, _, _, _ = me.separation.bss_eval_sources(reference_sources, mix_sources, compute_permutation=True)\n",
    "    \n",
    "    return sdr1 - sdr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, sir, sar, _ = me.separation.bss_eval_sources(reference_sources, estimated_sources, compute_permutation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227.98471633, 227.98471633])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.10238682, 4.10238682])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.18227768, 8.18227768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_out = nsdr(reference_sources, estimated_sources, mix_sources)\n",
    "nsdr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Image to spatial distortion\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_images(reference_sources, estimated_sources, compute_permutation=True)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **isr:** ```np.ndarray, shape=(nsrc,)```, vector of source Image to Spatial distortion Ratios (ISR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "\n",
    "- perm: not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, isr, sir, sar, _ = me.separation.bss_eval_images(reference_sources, estimated_sources, compute_permutation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Image to spatial distortion framewise\n",
    "\n",
    "``` python\n",
    "mir_eval.separation.bss_eval_images_framewise(reference_sources, estimated_sources, window=1323000, hop=661500, compute_permutation=False)\n",
    "```\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- **sdr:** ```np.ndarray, shape=(nsrc,)```, vector of Signal to Distortion Ratios (SDR)\n",
    "\n",
    "\n",
    "- **sir:** ```np.ndarray, shape=(nsrc,)```, vector of Source to Interference Ratios (SIR)\n",
    "\n",
    "\n",
    "- **sar:** ```np.ndarray, shape=(nsrc,)```, vector of Sources to Artifacts Ratios (SAR)\n",
    "\n",
    "\n",
    "- perm: not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, isr, sir, sar, _ = me.separation.bss_eval_images_framewise(reference_sources, \n",
    "                                                              estimated_sources, \n",
    "                                                              window=1323000, \n",
    "                                                              hop=661500, \n",
    "                                                              compute_permutation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Evaluate all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NSDR Vocal': 8.182277682555021,\n",
       " 'NSDR Instrumental': None,\n",
       " 'SIR Vocal': 227.98471632599598,\n",
       " 'SIR Instrumental': None,\n",
       " 'SAR Vocal': 4.10238682484913,\n",
       " 'SAR Instrumental': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, sirs, sars, _ = me.separation.bss_eval_sources(reference_sources, \n",
    "                                                     estimated_sources, \n",
    "                                                     compute_permutation=True)\n",
    "\n",
    "nsdrs = nsdr(reference_sources, estimated_sources, mix_sources)\n",
    "\n",
    "means = {\n",
    "    'NSDR Vocal': np.mean(nsdrs),\n",
    "    'NSDR Instrumental': None,\n",
    "    'SIR Vocal': np.mean(sirs),\n",
    "    'SIR Instrumental': None,\n",
    "    'SAR Vocal': np.mean(sars),\n",
    "    'SAR Instrumental': None\n",
    "}\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Comparison with MIREX results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirex_results = {\n",
    "    'NSDR Vocal': 8.681,\n",
    "    'NSDR Instrumental': 7.945,\n",
    "    'SIR Vocal': 15.308,\n",
    "    'SIR Instrumental': 21.975,\n",
    "    'SAR Vocal': 11.301,\n",
    "    'SAR Instrumental': 15.462\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAR accompaniment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.518666458560723"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_mean = np.mean(sar_acc)\n",
    "sar_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.437889310312546"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_mean = np.mean(nsdr_out)\n",
    "nsdr_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAR vocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.589121823444003"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_mean = np.mean(sar_vocal)\n",
    "sar_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.059249031308422"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_mean = np.mean(sar_vocal)\n",
    "sar_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.494788654034133"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_mean = np.mean(sar_vocal)\n",
    "sar_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.625165600337708"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_mean = np.mean(sar_vocal)\n",
    "sar_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.402809203017183"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_mean = np.mean(sar_vocal)\n",
    "sar_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NSDR Vocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.221848982066094"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_mean = np.mean(nsdr_out)\n",
    "nsdr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2116603344498517"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_mean = np.mean(nsdr_out)\n",
    "nsdr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.47433633604592"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_mean = np.mean(nsdr_out)\n",
    "nsdr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.225159956139196"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_mean = np.mean(nsdr_out)\n",
    "nsdr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.275659510817157"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdr_mean = np.mean(nsdr_out)\n",
    "nsdr_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
