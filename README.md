# Singing-voice-speration-with-U-Net
The purpose of this project is to decompose a music audio signal into its vocal and backing track components. Once decomposed, clean vocal or backing signals are useful for other MIR tasks such as singer identification, lyric transcription, and karaoke application [1]. While there are traditional methods for doing source separation of musical audio, deep learning models have emerged as powerful alternatives. In [1], the authors propose a method for decomposing music audio signals into a backing track using modified convolutional neural networks called U-Net [2]. While U-Net was developed for biomedical imaging [2,3], this architecture can be used in the context of singing voice separation. The results of experimentation in [1] shows that U-Net achieves better performance than the other state-of-the-art deep learning technique. We find this paper [1] would be interesting to prove, especially from a video in [4], where the presenter uses U-Net to show how clean this technique does voice separation.
